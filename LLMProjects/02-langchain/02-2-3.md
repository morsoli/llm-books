æœ¬ç”µå­ä¹¦å¼€æºï¼Œæ¬¢è¿ star ğŸŒŸï¼Œå…³æ³¨ã€ŠLLM åº”ç”¨å¼€å‘å®è·µç¬”è®°ã€‹

> **äº¤æµç¾¤** åˆ›å»ºäº†ä¸€ä¸ªLLMåº”ç”¨å¼€å‘äº¤æµç¾¤ï¼Œæœ‰éœ€è¦çš„å¯ä»¥é€‰æ‹©åŠ å…¥
![](../images/group.png)

## LangChainæ¨¡å—ä¹‹[Callbacks](https://python.langchain.com/docs/modules/callbacks/)
å›è°ƒæ¨¡å—å…è®¸æ¥åˆ°LLMåº”ç”¨ç¨‹åºçš„å„ä¸ªé˜¶æ®µï¼Œé‰´äºLLMçš„å¹»è§‰é—®é¢˜ï¼Œè¿™å¯¹äºæ—¥å¿—è®°å½•ã€ç›‘è§†ã€æµå¼å¤„ç†å’Œå…¶ä»–ä»»åŠ¡éå¸¸æœ‰ç”¨ï¼Œç°åœ¨ä¹Ÿæœ‰ä¸“ç”¨çš„å·¥å…·Heliconeï¼ŒArize AIç­‰äº§å“å¯ç”¨ï¼Œå…·ä½“çœ‹[LLMåº”ç”¨ç”Ÿæ€åˆåˆ›å…¬å¸è¯´æ˜](../ref/company.md)


### è‡ªå®šä¹‰å›è°ƒå¯¹è±¡
æ‰€æœ‰çš„å›è°ƒå¯¹è±¡éƒ½æ˜¯åŸºäºè¿™ä¸ªåŸºç±»æ¥å£°æ˜çš„
```python
class BaseCallbackHandler:
    """Base callback handler that can be used to handle callbacks from langchain."""

    def on_llm_start(
        self, serialized: Dict[str, Any], prompts: List[str], **kwargs: Any
    ) -> Any:
        """Run when LLM starts running."""

    def on_chat_model_start(
        self, serialized: Dict[str, Any], messages: List[List[BaseMessage]], **kwargs: Any
    ) -> Any:
        """Run when Chat Model starts running."""

    def on_llm_new_token(self, token: str, **kwargs: Any) -> Any:
        """Run on new LLM token. Only available when streaming is enabled."""

    def on_llm_end(self, response: LLMResult, **kwargs: Any) -> Any:
        """Run when LLM ends running."""

    def on_llm_error(
        self, error: Union[Exception, KeyboardInterrupt], **kwargs: Any
    ) -> Any:
        """Run when LLM errors."""

    def on_chain_start(
        self, serialized: Dict[str, Any], inputs: Dict[str, Any], **kwargs: Any
    ) -> Any:
        """Run when chain starts running."""

    def on_chain_end(self, outputs: Dict[str, Any], **kwargs: Any) -> Any:
        """Run when chain ends running."""

    def on_chain_error(
        self, error: Union[Exception, KeyboardInterrupt], **kwargs: Any
    ) -> Any:
        """Run when chain errors."""

    def on_tool_start(
        self, serialized: Dict[str, Any], input_str: str, **kwargs: Any
    ) -> Any:
        """Run when tool starts running."""

    def on_tool_end(self, output: str, **kwargs: Any) -> Any:
        """Run when tool ends running."""

    def on_tool_error(
        self, error: Union[Exception, KeyboardInterrupt], **kwargs: Any
    ) -> Any:
        """Run when tool errors."""

    def on_text(self, text: str, **kwargs: Any) -> Any:
        """Run on arbitrary text."""

    def on_agent_action(self, action: AgentAction, **kwargs: Any) -> Any:
        """Run on agent action."""

    def on_agent_finish(self, finish: AgentFinish, **kwargs: Any) -> Any:
        """Run on agent end."""
```

### ä½¿ç”¨å›è°ƒçš„ä¸¤ç§æ–¹å¼
- æ„é€ å‡½æ•°æ—¶å®šä¹‰å›è°ƒï¼šåœ¨æ„é€ å‡½æ•°ä¸­å®šä¹‰ï¼Œä¾‹å¦‚`LLMChain(callbacks=[handler], tags=['a-tag'])`ï¼Œå®ƒå°†è¢«ç”¨äºå¯¹è¯¥å¯¹è±¡çš„æ‰€æœ‰è°ƒç”¨ï¼Œå¹¶ä¸”å°†åªé’ˆå¯¹è¯¥å¯¹è±¡ï¼Œä¾‹å¦‚ï¼Œå¦‚æœä½ å‘LLMChainæ„é€ å‡½æ•°ä¼ é€’ä¸€ä¸ªhandlerï¼Œå®ƒå°†ä¸ä¼šè¢«é™„å±äºè¯¥é“¾çš„Modelä½¿ç”¨ã€‚
- è¯·æ±‚å‡½æ•°æ—¶ä¼ å…¥å›è°ƒï¼šå®šä¹‰åœ¨ç”¨äºå‘å‡ºè¯·æ±‚çš„call()/run()/apply()æ–¹æ³•ä¸­ï¼Œä¾‹å¦‚`chain.call(inputs, callbacks=[handler])`ï¼Œå®ƒå°†ä»…ç”¨äºè¯¥ç‰¹å®šè¯·æ±‚ï¼Œä»¥åŠå®ƒæ‰€åŒ…å«çš„æ‰€æœ‰å­è¯·æ±‚ï¼ˆä¾‹å¦‚ï¼Œå¯¹LLMChainçš„è°ƒç”¨ä¼šè§¦å‘å¯¹Modelçš„è°ƒç”¨ï¼ŒModelä¼šä½¿ç”¨call()æ–¹æ³•ä¸­ä¼ é€’çš„ç›¸åŒ handlerï¼‰ã€‚

ä¸‹é¢è¿™æ˜¯é‡‡ç”¨æ„é€ å‡½æ•°å®šä¹‰å›è°ƒçš„ä¾‹å­ï¼š
```python
class MyCustomSyncHandler(BaseCallbackHandler):
    def on_llm_new_token(self, token: str, **kwargs) -> None:
        print(f"åŒæ­¥å›è°ƒè¢«è°ƒç”¨: token: {token}")


class MyCustomAsyncHandler(AsyncCallbackHandler):
    async def on_llm_start(
        self, serialized: Dict[str, Any], prompts: List[str], **kwargs: Any
    ) -> None:
        """Run when chain starts running."""
        print("LLMè°ƒç”¨å¼€å§‹....")
        await asyncio.sleep(0.3)
        print("Hi! I just woke up. Your llm is starting")

    async def on_llm_end(self, response: LLMResult, **kwargs: Any) -> None:
        """Run when chain ends running."""
        print("LLMè°ƒç”¨ç»“æŸ....")
        await asyncio.sleep(0.3)
        print("Hi! I just woke up. Your llm is ending")


if __name__ == "__main__":
    chat = ChatOpenAI(
        max_tokens=25,
        streaming=True,
        callbacks=[MyCustomSyncHandler(), MyCustomAsyncHandler()],
    )

    asyncio.run(chat.agenerate([[HumanMessage(content="è®²ä¸ªç¬‘è¯")]]))
```

### å‚è€ƒèµ„æ–™
1. [æ–¯å¦ç¦é—®ç­”æ•°æ®é›†](https://rajpurkar.github.io/SQuAD-explorer/)