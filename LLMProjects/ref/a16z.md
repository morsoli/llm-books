æœ¬ç”µå­ä¹¦å¼€æºï¼Œæ¬¢è¿ star ğŸŒŸï¼Œå…³æ³¨ã€ŠLLM åº”ç”¨å¼€å‘å®è·µç¬”è®°ã€‹

æˆ‘çš„æ–°ä¹¦[ã€ŠLangChainç¼–ç¨‹ä»å…¥é—¨åˆ°å®è·µã€‹](https://u.jd.com/V8pkqFY) å·²ç»å¼€å”®ï¼æ¨èæ­£åœ¨å­¦ä¹ AIåº”ç”¨å¼€å‘çš„æœ‹å‹è´­ä¹°é˜…è¯»ï¼
[![LangChainç¼–ç¨‹ä»å…¥é—¨åˆ°å®è·µ](../../images/langchain-book.jpg "LangChainç¼–ç¨‹ä»å…¥é—¨åˆ°å®è·µ")](https://u.jd.com/V8pkqFY) 
 

## A16Zæ¨èçš„AIå­¦ä¹ æ¸…å•


ä¸‹é¢A16Zæ•´ç†çš„ä¸€ä»½äººå·¥æ™ºèƒ½é¢†åŸŸçš„å­¦ä¹ æ¸…å•ï¼Œæ¶µç›–å„ä¸ªæ–¹é¢ï¼Œæ¯ä¸€ç¯‡éƒ½æ˜¯è¯¥é¢†åŸŸçš„ç»å…¸ä¹‹ä½œã€‚ä»ä»‹ç»ç¥ç»ç½‘ç»œã€Transformerå’Œå¤§æ¨¡å‹å¼€å§‹ï¼ŒåŒ…æ‹¬LLMæ„å»ºå®è·µæŒ‡å—ã€æç¤ºå·¥ç¨‹å’Œå¸‚åœºåˆ†æï¼Œæœ€ååˆ—ä¸¾äº†å…·æœ‰é‡Œç¨‹ç¢‘æ„ä¹‰çš„ç ”ç©¶æˆæœè®ºæ–‡åˆ—è¡¨ã€‚è¿™æ˜¯ä¸€ä»½éå¸¸ä¸é”™çš„ç”±æµ…å…¥æ·±çš„å­¦ä¹ è·¯å¾„ï¼Œä¹Ÿæ˜¯éå¸¸æœ‰ä»·å€¼çš„å­¦ä¹ èµ„æºï¼Œä»åˆå­¦è€…åˆ°ä¸“ä¸šäººå£«éƒ½å¯ä»¥ä»ä¸­å—ç›Šï¼Œå¸Œæœ›å¯¹å¤§å®¶æœ‰æ‰€å¸®åŠ©ã€‚

---
## è½»æ¾å…¥é—¨ğŸ¥³
> è¿™äº›æ–‡ç« ä¸éœ€è¦ä¸“é—¨çš„èƒŒæ™¯çŸ¥è¯†ï¼Œå¯ä»¥å¸®åŠ©ä½ å¿«é€Ÿç†è§£ç°ä»£AIæµªæ½®çš„æœ€é‡è¦éƒ¨åˆ†ã€‚

**[Software 2.0](https://karpathy.medium.com/software-2-0-a64152b37c35)** ï¼šAndrej Karpathyæ˜¯æœ€æ—©æ¸…æ¥šè§£é‡Šï¼ˆåœ¨2017å¹´ï¼ï¼‰ä¸ºä»€ä¹ˆæ–°çš„AIæµªæ½®çœŸæ­£é‡è¦çš„äººä¹‹ä¸€ã€‚ä»–çš„è®ºç‚¹æ˜¯ï¼ŒAIæ˜¯ä¸€ç§æ–°çš„ã€å¼ºå¤§çš„ç¼–ç¨‹è®¡ç®—æœºçš„æ–¹å¼ã€‚éšç€å¤§è¯­è¨€æ¨¡å‹(LLMs)çš„å¿«é€Ÿæ”¹è¿›ï¼Œè¿™ä¸ªè®ºç‚¹è¢«è¯æ˜æ˜¯æœ‰å…ˆè§ä¹‹æ˜çš„ï¼Œå¹¶ä¸ºAIå¸‚åœºçš„å¯èƒ½è¿›å±•æä¾›äº†ä¸€ä¸ªè‰¯å¥½çš„æ€ç»´æ¨¡å‹ã€‚[ä¸­æ–‡ç¿»è¯‘ï¼šé¢ è¦†å¼ç¼–ç¨‹ï¼šè½¯ä»¶2.0](https://zhuanlan.zhihu.com/p/366808383)

**[State of GPT](https://build.microsoft.com/en-US/sessions/db3f4859-cd30-4445-a0cd-553c3304f8e2)** ï¼šè¿™ä¹Ÿæ˜¯Karpathyçš„æ–‡ç« ï¼Œè¿™æ˜¯ä¸€ä¸ªéå¸¸å®¹æ˜“ç†è§£çš„è§£é‡Šï¼Œè¯´æ˜äº†ChatGPT / GPTæ¨¡å‹ä¸€èˆ¬å¦‚ä½•å·¥ä½œï¼Œå¦‚ä½•ä½¿ç”¨å®ƒä»¬ï¼Œä»¥åŠç ”å‘å¯èƒ½é‡‡å–çš„æ–¹å‘ã€‚[ä¸­æ–‡ç¿»è¯‘ï¼šState of GPTï¼šå¤§ç¥Andrejæ­ç§˜OpenAIå¤§æ¨¡å‹åŸç†å’Œè®­ç»ƒè¿‡ç¨‹](https://mp.weixin.qq.com/s?__biz=MzIxODUzNTg2MA==&mid=2247485342&idx=1&sn=770152ca8a00f2e3d87ed2a09e131e11)

**[What is ChatGPT doing â€¦ and why does it work?](https://writings.stephenwolfram.com/2023/02/what-is-chatgpt-doing-and-why-does-it-work/)** ï¼šè®¡ç®—æœºç§‘å­¦å®¶å’Œä¼ä¸šå®¶Stephen Wolframç»™å‡ºäº†ä¸€ç¯‡é•¿è€Œæ˜“è¯»çš„è§£é‡Šï¼Œä»ä¸€å¼€å§‹çš„åŸç†è§£é‡Šäº†ç°ä»£AIæ¨¡å‹æ˜¯å¦‚ä½•å·¥ä½œçš„ã€‚ä»–è·Ÿéšä»æ—©æœŸç¥ç»ç½‘ç»œåˆ°ä»Šå¤©çš„LLMså’ŒChatGPTçš„æ—¶é—´çº¿ã€‚[ä¸­æ–‡ç¿»è¯‘ï¼šChatGPTåœ¨åšä»€ä¹ˆ...ä¸ºä»€ä¹ˆå®ƒèƒ½å¤ŸæˆåŠŸ](https://zhuanlan.zhihu.com/p/607601817)

**[Transformers, explained](https://daleonai.com/transformers-explained)** ï¼šè¿™ç¯‡æ–‡ç« ç”±Dale Markowitzæ’°å†™ï¼Œæ˜¯å¯¹â€œä»€ä¹ˆæ˜¯LLMï¼Œå®ƒæ˜¯å¦‚ä½•å·¥ä½œçš„ï¼Ÿâ€è¿™ä¸ªé—®é¢˜çš„ä¸€ä¸ªæ›´çŸ­ã€æ›´ç›´æ¥çš„å›ç­”ã€‚è¿™æ˜¯ä¸€ç§å¾ˆå¥½çš„æ–¹å¼ï¼Œå¯ä»¥è½»æ¾åœ°è¿›å…¥è¿™ä¸ªä¸»é¢˜ï¼Œå¹¶å¯¹è¿™é¡¹æŠ€æœ¯å»ºç«‹ç›´è§‚ç†è§£ã€‚è¿™ç¯‡æ–‡ç« æ˜¯å…³äºGPT-3çš„ï¼Œä½†ä»é€‚ç”¨äºæ–°çš„æ¨¡å‹ã€‚[ä¸­æ–‡ç¿»è¯‘ï¼šè§£æTansformeræ¨¡å‹â€”ç†è§£GPT-3, BERTå’ŒT5èƒŒåçš„æ¨¡å‹](https://mp.weixin.qq.com/s/kfsW7ccYUAGp1AHWWF6c1w)ï¼Œè¯´æ˜äº†Transformeræ¨¡å‹ä¸­çš„ä¸‰ä¸ªæ ¸å¿ƒç»„æˆéƒ¨åˆ†ï¼šä½ç½®ç¼–ç ã€æ³¨æ„åŠ›æœºåˆ¶å’Œè‡ªæ³¨æ„åŠ›æœºåˆ¶çš„å«ä¹‰ï¼Œå®ƒä»¬å…±åŒä½œç”¨äºè¾“å…¥åºåˆ—ï¼Œä½¿å¾—æ¨¡å‹å¯ä»¥æ›´å¥½åœ°å¤„ç†åºåˆ—æ•°æ®ï¼Œå¹¶åœ¨NLPå’Œå…¶ä»–åºåˆ—æ•°æ®å¤„ç†ä»»åŠ¡ä¸­å–å¾—å¾ˆå¥½çš„è¡¨ç°

**[How Stable Diffusion works](https://mccormickml.com/2022/12/21/how-stable-diffusion-works/)** ï¼šè¿™æ˜¯ä¸€ç¯‡ä¸ä¸Šä¸€ç¯‡æ–‡ç« åœ¨è®¡ç®—æœºè§†è§‰é¢†åŸŸçš„å¯¹åº”æ–‡ç« ã€‚Chris McCormickä¸ºéä¸“ä¸šäººå£«è§£é‡Šäº†Stable Diffusionæ˜¯å¦‚ä½•å·¥ä½œçš„ï¼Œå¹¶ä»æ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹çš„è§’åº¦ï¼Œå¸®åŠ©ä½ å¯¹è¿™ç§æŠ€æœ¯å»ºç«‹ç›´è§‚ç†è§£ã€‚å¦‚æœä½ å¸Œæœ›æ›´è½»æ¾åœ°ç†è§£è¿™ä¸ªæ¦‚å¿µï¼Œå¯ä»¥æŸ¥çœ‹æ¥è‡ªr/StableDiffusionçš„è¿™ä¸ª[æ¼«ç”»](https://www.reddit.com/r/StableDiffusion/comments/zs5dk5/i_made_an_infographic_to_explain_how_stable/)ã€‚(è¿™éƒ¨åˆ†æˆ‘æ›´æ¨è çŸ¥ä¹@å°å°å°† å†™çš„æ–‡ç« ï¼Œå¯¹ç…§ä»£ç è®²çš„å¾ˆæ¸…æ¥šï¼Œ[æ–‡ç”Ÿå›¾æ¨¡å‹ä¹‹Stable Diffusion](https://zhuanlan.zhihu.com/p/617134893))

## åŸºç¡€å­¦ä¹ ï¼šç¥ç»ç½‘ç»œã€åå‘ä¼ æ’­å’ŒåµŒå…¥ğŸ’ª

> è¿™äº›èµ„æºä¸ºä½ æä¾›äº†æœºå™¨å­¦ä¹ å’ŒAIåŸºæœ¬æ¦‚å¿µçš„åŸºç¡€ç†è§£ï¼Œä»æ·±åº¦å­¦ä¹ çš„åŸºç¡€çŸ¥è¯†åˆ°AIä¸“å®¶çš„å¤§å­¦æ°´å¹³è¯¾ç¨‹ã€‚

**[Deep learning in a nutshell: core concepts](https://developer.nvidia.com/blog/deep-learning-nutshell-core-concepts/)** ï¼šè¿™æ˜¯Nvidiaçš„å››éƒ¨åˆ†ç³»åˆ—æ–‡ç« ï¼Œä»‹ç»äº†2015å¹´å®è·µä¸­çš„æ·±åº¦å­¦ä¹ åŸºç¡€ï¼Œå¯¹äºåˆšå¼€å§‹å­¦ä¹ AIçš„äººæ¥è¯´æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„èµ„æºã€‚

**[Practical deep learning for coders](https://course.fast.ai/)** ï¼šé€šè¿‡å®ç”¨çš„ä¾‹å­å’Œä»£ç ï¼Œè§£é‡Šäº†AIåŸºç¡€çŸ¥è¯†çš„å…¨é¢ã€å…è´¹çš„è¯¾ç¨‹ã€‚

**[Word2vec explained](https://towardsdatascience.com/word2vec-explained-49c52b4ccb71)** ï¼šå¯¹åµŒå…¥å’Œä»¤ç‰Œçš„ç®€å•ä»‹ç»ï¼Œå®ƒä»¬æ˜¯LLMsï¼ˆå’Œæ‰€æœ‰è¯­è¨€æ¨¡å‹ï¼‰çš„æ„å»ºå—ã€‚

**[Yes you should understand backprop](https://karpathy.medium.com/yes-you-should-understand-backprop-e2f06eab496b)** ï¼šå¦‚æœä½ æƒ³ç†è§£ç»†èŠ‚ï¼Œè¿™æ˜¯å…³äºåå‘ä¼ æ’­æ›´æ·±å…¥çš„æ–‡ç« ã€‚å¦‚æœä½ æƒ³äº†è§£æ›´å¤šï¼Œå¯ä»¥çœ‹çœ‹[Youtube ä¸Šçš„Stanford CS231n è®²åº§](https://www.youtube.com/watch?v=i94OvYb6noo)ã€‚

### è¯¾ç¨‹
**[Stanford CS229](https://www.youtube.com/playlist?list=PLoROMvodv4rMiGQp3WXShtMGgzqpfVfbU)** ï¼šAndrew Ngçš„æœºå™¨å­¦ä¹ å…¥é—¨è¯¾ç¨‹ï¼Œè¦†ç›–äº†æœºå™¨å­¦ä¹ çš„åŸºç¡€çŸ¥è¯†ã€‚

**[Stanford CS224N](https://www.youtube.com/playlist?list=PLoROMvodv4rOSH4v6133s9LFPRHjEmbmJ)** ï¼šChris Manningçš„æ·±åº¦å­¦ä¹ è‡ªç„¶è¯­è¨€å¤„ç†(NLP)è¯¾ç¨‹ï¼Œé€šè¿‡ç¬¬ä¸€ä»£ LLM ä»‹ç»æ¶µç›–äº† NLP åŸºç¡€çŸ¥è¯†ã€‚

## æŠ€æœ¯æ·±åº¦æ¢è®¨ï¼šäº†è§£transformerså’Œå¤§æ¨¡å‹ğŸ¤¯

> æœ‰æ— æ•°çš„èµ„æºï¼ˆæœ‰äº›å†…å®¹æ›´å¥½äº›ï¼‰è¯•å›¾è§£é‡Šå¤§è¯­è¨€æ¨¡å‹(LLMs)çš„å·¥ä½œåŸç†ã€‚ä»¥ä¸‹æ˜¯æˆ‘ä»¬çš„ä¸€äº›æœ€çˆ±ï¼Œé¢å‘å¹¿æ³›çš„è¯»è€…/è§‚ä¼—ã€‚

**[The illustrated transformer](https://jalammar.github.io/illustrated-transformer/)** ï¼šJay Alammar å¯¹transformeræ¶æ„çš„æ›´å¤šæŠ€æœ¯æ¦‚è¿°ã€‚

**[The annotated transformer](http://nlp.seas.harvard.edu/annotated-transformer/)** ï¼šå¦‚æœä½ æƒ³åœ¨æºä»£ç çº§åˆ«ç†è§£transformeræ¨¡å‹ï¼Œè¿™æ˜¯ä¸€ç¯‡æ·±åº¦æ–‡ç« ã€‚éœ€è¦ä¸€äº›PyTorchçš„çŸ¥è¯†ã€‚

**[Letâ€™s build GPT: from scratch, in code, spelled out](https://www.youtube.com/watch?v=kCc8FmEb1nY)** ï¼šä»é›¶å¼€å§‹ï¼Œé€šè¿‡ä»£ç ï¼Œè¯¦ç»†è§£é‡Šï¼šå¯¹äºå·¥ç¨‹å¸ˆä»¬ï¼ŒKarpathyåšäº†ä¸€ä¸ªå¦‚ä½•æ„å»ºGPTæ¨¡å‹çš„è§†é¢‘æ¼”ç¤ºã€‚

**[The illustrated Stable Diffusion](https://jalammar.github.io/illustrated-stable-diffusion/)**** ï¼š**å¯¹æ½œåœ¨æ‰©æ•£æ¨¡å‹çš„ä»‹ç»ï¼Œè¿™æ˜¯æœ€å¸¸è§çš„ç”¨äºå›¾åƒç”Ÿæˆçš„AIæ¨¡å‹ã€‚

**[RLHF: Reinforcement Learning from Human Feedback](https://huyenchip.com/2023/05/02/rlhf.html)** ï¼šChip Huyenè§£é‡Šäº†RLHFï¼ˆåŸºäºäººç±»åé¦ˆçš„å¼ºåŒ–å­¦ä¹  ï¼‰ï¼Œå®ƒå¯ä»¥ä½¿LLMsçš„è¡Œä¸ºæ›´å¯é¢„æµ‹ã€æ›´ç¬¦åˆäººç±»çš„å‹å¥½æ–¹å¼ã€‚è¿™æ˜¯åƒChatGPTè¿™æ ·çš„ç³»ç»Ÿä¸­æœ€é‡è¦ä½†æœ€ä¸å¥½ç†è§£çš„æ–¹é¢ä¹‹ä¸€ã€‚

**[Reinforcement learning from human feedback](https://www.youtube.com/watch?v=hhiLw5Q_UFg)** ï¼šè®¡ç®—æœºç§‘å­¦å®¶å’ŒOpenAIè”åˆåˆ›å§‹äººJohn Shulmanåœ¨è¿™ä¸ªç²¾å½©çš„æ¼”è®²ä¸­æ›´æ·±å…¥åœ°æ¢è®¨äº†LLMsï¼ˆå¤§è¯­è¨€æ¨¡å‹ï¼‰ä¸RLHFï¼ˆåŸºäºäººç±»åé¦ˆçš„å¼ºåŒ–å­¦ä¹  ï¼‰çš„å½“å‰çŠ¶æ€ã€è¿›å±•å’Œé™åˆ¶ã€‚

### è¯¾ç¨‹

**[Stanford CS25](https://www.youtube.com/watch?v=P127jhj-8-Y)** ï¼šTransformeræŠ€æœ¯è”ç›Ÿï¼Œå…³äºTransformeræŠ€æœ¯çš„åœ¨çº¿ç ”è®¨ä¼šã€‚

**[Stanford CS324](https://stanford-cs324.github.io/winter2022/)** ï¼šç”±Percy Liang, Tatsu Hashimotoå’ŒChris Reä¸»è®²çš„ã€Šå¤§å‹è¯­è¨€æ¨¡å‹ã€‹è¯¾ç¨‹ï¼Œæ¶µç›–äº†å¤§å‹è¯­è¨€æ¨¡å‹çš„å„ç§æŠ€æœ¯å’ŒéæŠ€æœ¯æ–¹é¢ã€‚

### å‚è€ƒå’Œè¯„è®º

**[Predictive learning, NIPS 2016](https://www.youtube.com/watch?v=Ount2Y4qxQo&t=1072s)** ï¼šåœ¨è¿™æ¬¡æ—©æœŸçš„æ¼”è®²ä¸­ï¼ŒYann LeCunå¼ºçƒˆä¸»å¼ æ— ç›‘ç£å­¦ä¹ æ˜¯å¤§è§„æ¨¡AIæ¨¡å‹æ¶æ„çš„å…³é”®å…ƒç´ ã€‚è·³åˆ°[19:20](https://youtu.be/Ount2Y4qxQo?t=1160)æŸ¥çœ‹ä»–è‘—åçš„è›‹ç³•ç±»æ¯”ï¼Œè¿™ä»ç„¶æ˜¯ç°ä»£AIæœ€å¥½çš„å¿ƒæ™ºæ¨¡å‹ä¹‹ä¸€ã€‚

**[AI for full-self driving at Tesla:](https://www.youtube.com/watch?v=hx7BXih7zx8)** ï¼šå¦ä¸€ä¸ªç»å…¸çš„Karpathyæ¼”è®²ï¼Œè¿™æ¬¡ä»–ä»‹ç»äº†ç‰¹æ–¯æ‹‰çš„æ•°æ®æ”¶é›†å¼•æ“ã€‚ä»[8:35](https://youtu.be/hx7BXih7zx8?t=515)å¼€å§‹ï¼Œä»–è¿›è¡Œäº†ä¸€æ¬¡ä¼Ÿå¤§çš„AIæ¼”è®²ï¼Œè§£é‡Šäº†ä¸ºä»€ä¹ˆé•¿å°¾é—®é¢˜ï¼ˆåœ¨è¿™ç§æƒ…å†µä¸‹æ˜¯åœè½¦æ ‡å¿—æ£€æµ‹ï¼‰å¦‚æ­¤å›°éš¾ã€‚

**[The scaling hypothesis](https://gwern.net/scaling-hypothesis)** ï¼šå¤§å‹è¯­è¨€æ¨¡å‹æœ€ä»¤äººæƒŠè®¶çš„æ–¹é¢ä¹‹ä¸€ï¼šè§„æ¨¡åŒ–ï¼ˆå¢åŠ æ›´å¤šçš„æ•°æ®å’Œè®¡ç®—ï¼‰ä¼šç»§ç»­æé«˜å‡†ç¡®æ€§ã€‚GPT-3æ˜¯ç¬¬ä¸€ä¸ªæ¸…æ¥šå±•ç¤ºè¿™ä¸€ç‚¹çš„æ¨¡å‹ï¼ŒGwernçš„æ–‡ç« å¾ˆå¥½åœ°è§£é‡Šäº†å…¶èƒŒåçš„ç›´è§‰ã€‚

**[Chinchilla's wild implications](https://www.lesswrong.com/posts/6Fpvch8RR29qLEWNH/chinchilla-s-wild-implications)** ï¼šåä¹‰ä¸Šæ˜¯å¯¹é‡è¦çš„Chinchillaè®ºæ–‡çš„è§£é‡Šï¼Œè¿™ç¯‡æ–‡ç« è§¦åŠäº†LLMè§„æ¨¡åŒ–çš„å¤§é—®é¢˜çš„æ ¸å¿ƒï¼šæˆ‘ä»¬æ˜¯å¦æ­£åœ¨è€—å°½æ•°æ®ï¼Ÿè¿™ç¯‡æ–‡ç« åœ¨ä¸Šé¢æ–‡ç« çš„åŸºç¡€ä¸Šï¼Œç»™å‡ºäº†å¯¹è§„æ¨¡åŒ–è§„å¾‹çš„æ–°é²œè§†è§’ã€‚

**[A survey of large language models](https://arxiv.org/pdf/2303.18223v4.pdf)** ï¼šå¯¹å½“å‰LLMçš„å…¨é¢åˆ†æï¼ŒåŒ…æ‹¬å‘å±•æ—¶é—´çº¿ã€è§„æ¨¡ã€è®­ç»ƒç­–ç•¥ã€è®­ç»ƒæ•°æ®ã€ç¡¬ä»¶ç­‰ã€‚

**[Sparks of artificial general intelligence: Early experiments with GPT-4](https://arxiv.org/abs/2303.12712)** ï¼šå¾®è½¯ç ”ç©¶éƒ¨å¯¹å½“å‰æœ€å…ˆè¿›çš„LLMï¼ˆGPT-4ï¼‰ç›¸å¯¹äºäººç±»æ™ºèƒ½èƒ½åŠ›çš„æ—©æœŸåˆ†æã€‚

**[The AI revolution: How Auto-GPT unleashes a new era of automation and creativity](https://pub.towardsai.net/the-ai-revolution-how-auto-gpt-unleashes-a-new-era-of-automation-and-creativity-2008aa2ca6ae)** ï¼šä»‹ç»Auto-GPTå’ŒAI Agentsã€‚è¿™é¡¹æŠ€æœ¯è¿˜å¾ˆæ—©æœŸï¼Œä½†é‡è¦çš„æ˜¯è¦ç†è§£å®ƒâ€”â€”å®ƒä½¿ç”¨äº’è”ç½‘è®¿é—®å’Œè‡ªæˆ‘ç”Ÿæˆçš„å­ä»»åŠ¡æ¥è§£å†³ç‰¹å®šçš„ã€å¤æ‚çš„é—®é¢˜æˆ–ç›®æ ‡ã€‚

**[The Waluigi Effect](https://www.lesswrong.com/posts/D7PumeYTDPfBTp3i7/the-waluigi-effect-mega-post)** ï¼šåä¹‰ä¸Šæ˜¯å¯¹â€œWaluigi æ•ˆåº”â€çš„è§£é‡Šï¼ˆå³ï¼Œä¸ºä»€ä¹ˆLLMè¡Œä¸ºä¸­ä¼šå‡ºç°â€œå¦æˆ‘â€ï¼‰ã€æ³¨ï¼šåœ¨å›åº”ä¸åŒçš„æç¤ºæˆ–é—®é¢˜æ—¶ï¼Œå®ƒå¯èƒ½ä¼šè¡¨ç°å‡ºä¸åŒçš„â€œä¸ªæ€§â€æˆ–â€œè§’è‰²â€ã€‘çš„è§£é‡Šï¼Œä½†å…¶ä¸»è¦çš„æœ‰è¶£ä¹‹å¤„åœ¨äºå®ƒå¯¹LLMæç¤ºç†è®ºçš„æ·±å…¥ç ”ç©¶ã€‚

## ä½¿ç”¨ LLM è¿›è¡Œæ„å»ºçš„å®ç”¨æŒ‡å—ğŸ§‘ğŸ»â€ğŸ’»

> æ–°çš„åº”ç”¨æ ˆæ­£åœ¨ä»¥LLMä¸ºæ ¸å¿ƒå½¢æˆã€‚è™½ç„¶ç›®å‰è¿˜æ²¡æœ‰å¾ˆå¤šå…³äºæ­¤ä¸»é¢˜çš„æ­£è§„æ•™è‚²è¯¾ç¨‹ï¼Œä½†æˆ‘ä»¬æ‰¾åˆ°äº†ä¸€äº›æœ€æœ‰ç”¨çš„èµ„æºã€‚

**[Build a GitHub support bot with GPT3, LangChain, and Python](https://dagster.io/blog/chatgpt-langchain)** ï¼šè¿™æ˜¯å…³äºç°ä»£LLMåº”ç”¨æ ˆçš„æœ€æ—©çš„å…¬å¼€è§£é‡Šä¹‹ä¸€ã€‚è¿™é‡Œçš„ä¸€äº›å»ºè®®å¯èƒ½å·²ç»è¿‡æ—¶ï¼Œä½†åœ¨å¾ˆå¤šæ–¹é¢ï¼Œå®ƒå¼€å¯äº†æ–°ä¸€ä»£AIåº”ç”¨çš„å¹¿æ³›æ¥å—å’Œå®è·µã€‚

**[Building LLM applications for production](https://huyenchip.com/2023/04/11/llm-engineering.html)** ï¼šChip Huyenè®¨è®ºäº†æ„å»ºLLMåº”ç”¨çš„è®¸å¤šå…³é”®æŒ‘æˆ˜ï¼Œå¦‚ä½•è§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œä»¥åŠå“ªç§ç±»å‹çš„ç”¨ä¾‹æœ€æœ‰æ„ä¹‰ã€‚

**[Prompt Engineering Guide](https://www.promptingguide.ai/)** ï¼šå¯¹äºä»»ä½•ç¼–å†™LLMæç¤ºçš„äººâ€”â€”åŒ…æ‹¬åº”ç”¨å¼€å‘è€…â€”â€”è¿™æ˜¯æœ€å…¨é¢çš„æŒ‡å—ï¼Œå¯¹ä¸€äº›æµè¡Œæ¨¡å‹æä¾›äº†å…·ä½“ç¤ºä¾‹ã€‚å¦‚æœæƒ³è¦æ›´è½»æ¾ã€æ›´å¯Œæœ‰å¯¹è¯æ€§çš„å¤„ç†ï¼Œå¯ä»¥å°è¯•é˜…è¯»[Brexçš„æç¤ºå·¥ç¨‹æŒ‡å—](https://github.com/brexhq/prompt-engineering)ã€‚

**[Prompt injection: Whatâ€™s the worst that can happen?](https://simonwillison.net/2023/Apr/14/worst-that-can-happen/)** å¯èƒ½ä¼šå‘ç”Ÿä»€ä¹ˆæœ€ç³Ÿç³•çš„äº‹æƒ…ï¼Ÿæç¤ºæ³¨å…¥æ˜¯LLMåº”ç”¨æ½œåœ¨çš„ä¸¥é‡å®‰å…¨æ¼æ´ï¼Œç›®å‰è¿˜æ²¡æœ‰å®Œç¾çš„è§£å†³æ–¹æ¡ˆã€‚Simon Willisonåœ¨è¿™ç¯‡æ–‡ç« ä¸­å¯¹è¿™ä¸ªé—®é¢˜ç»™å‡ºäº†æœ€ç»ˆçš„æè¿°ã€‚Simonå…³äºAIçš„å‡ ä¹æ‰€æœ‰å†…å®¹éƒ½æ˜¯éå¸¸æ£’çš„ã€‚

**[OpenAI cookbook](https://github.com/openai/openai-cookbook/tree/main)** ï¼šå¯¹äºå¼€å‘è€…æ¥è¯´ï¼Œè¿™æ˜¯ä½¿ç”¨OpenAI APIçš„æŒ‡å—å’Œä»£ç ç¤ºä¾‹çš„æœ€æƒå¨æ”¶é›†ã€‚å®ƒä¼šä¸æ–­æ›´æ–°æ–°çš„ä»£ç ç¤ºä¾‹ã€‚

**[Pinecone learning center](https://www.pinecone.io/learn/)** ï¼šè®¸å¤šLLMåº”ç”¨éƒ½æ˜¯åŸºäºå‘é‡æœç´¢èŒƒå¼ã€‚å°½ç®¡Pineconeçš„å­¦ä¹ ä¸­å¿ƒæ˜¯å…¶å“ç‰Œæ‰€æä¾›çš„å†…å®¹ï¼Œä½†å®ƒæä¾›äº†å¦‚ä½•åœ¨è¿™ç§æ¨¡å¼ä¸­æ„å»ºçš„æœ€æœ‰ç”¨çš„æŒ‡å¯¼ã€‚

**[LangChain docs](https://python.langchain.com/en/latest/index.html)** ï¼šä½œä¸ºLLMåº”ç”¨çš„é»˜è®¤åè°ƒå±‚ï¼ŒLangChainå°†å †æ ˆä¸­çš„æ‰€æœ‰å…¶ä»–éƒ¨åˆ†è¿æ¥åœ¨ä¸€èµ·ã€‚å› æ­¤ï¼Œä»–ä»¬çš„æ–‡æ¡£å¯¹äºç†è§£æ•´ä¸ªæŠ€æœ¯æ ˆä»¥åŠå„éƒ¨åˆ†å¦‚ä½•ååŒå·¥ä½œæä¾›äº†å®ç”¨çš„å‚è€ƒã€‚

### è¯¾ç¨‹

**[LLM Bootcamp](https://fullstackdeeplearning.com/llm-bootcamp/)** ï¼šè¿™æ˜¯ä¸€ä¸ªå®è·µè¯¾ç¨‹ï¼Œç”±Charles Fryeã€Sergey Karayevå’ŒJosh Tobinä¸»å¯¼ï¼Œä¸“æ³¨äºæ„å»ºåŸºäºLLMçš„åº”ç”¨ã€‚

**[Hugging Face Transformers](https://huggingface.co/learn/nlp-course/chapter1/1)** ï¼šè¿™æ˜¯ä¸€ä¸ªæŒ‡å—ï¼Œæ•™ä½ å¦‚ä½•ä½¿ç”¨Hugging Face transformersåº“ä¸­çš„å¼€æºLLMã€‚

**LLMåŸºå‡†**

**[Chatbot Arena](https://lmsys.org/blog/2023-05-03-arena/)** ï¼šè¿™æ˜¯ä¸€ä¸ªç”±UC Berkeleyçš„å›¢é˜Ÿé¢†å¯¼çš„ï¼Œé‡‡ç”¨Eloè¯„åˆ†ç³»ç»Ÿå¯¹çƒ­é—¨LLMè¿›è¡Œæ’åçš„å¹³å°ã€‚ç”¨æˆ·ä¹Ÿå¯ä»¥é€šè¿‡è¿›è¡Œæ¨¡å‹é—´çš„ç›´æ¥æ¯”è¾ƒå‚ä¸å…¶ä¸­ã€‚

**[Open LLM Leaderboard](https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard)** ï¼šæ˜¯ä¸€ä¸ªç”±Hugging Faceæä¾›çš„æ’è¡Œæ¦œï¼Œæ¯”è¾ƒå¼€æºLLMåœ¨ä¸€ç³»åˆ—æ ‡å‡†åŸºå‡†å’Œä»»åŠ¡ä¸­çš„è¡¨ç°ã€‚

## é‡Œç¨‹ç¢‘å¼çš„ç ”ç©¶æˆæœğŸ”¬

> æˆ‘ä»¬ä»Šå¤©æ‰€è§çš„è®¸å¤šä»¤äººæƒŠå¥‡çš„AIäº§å“ï¼Œéƒ½æ˜¯ç”±å¤§å…¬å¸å’Œé¡¶çº§å¤§å­¦çš„ä¸“å®¶è¿›è¡Œçš„ä»¤äººæƒŠå¥‡çš„ç ”ç©¶æˆæœã€‚æœ€è¿‘ï¼Œæˆ‘ä»¬ä¹Ÿçœ‹åˆ°äº†ä¸ªäººå’Œå¼€æºç¤¾åŒºå¯¹æµè¡Œé¡¹ç›®è¿›è¡Œçš„å“è¶Šå·¥ä½œï¼Œä¾‹å¦‚ï¼Œé€šè¿‡åˆ›å»ºè‡ªåŠ¨åŒ–ä»£ç†æˆ–å°†å¤§æ¨¡å‹ç§»æ¤åˆ°ç®—åŠ›æ›´å¼±çš„ç¡¬ä»¶ä¸Šè¿è¡Œã€‚ä»¥ä¸‹æ˜¯è¿™äº›è®ºæ–‡å’Œé¡¹ç›®çš„é›†åˆï¼Œä¾›çœŸæ­£æƒ³æ·±å…¥ç ”ç©¶ç”Ÿæˆæ€§AIçš„äººå‚è€ƒã€‚ï¼ˆå¯¹äºç ”ç©¶è®ºæ–‡å’Œé¡¹ç›®ï¼Œæˆ‘ä»¬è¿˜åŒ…æ‹¬äº†ç›¸å…³çš„åšå®¢æ–‡ç« æˆ–ç½‘ç«™çš„é“¾æ¥ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰ï¼Œè¿™äº›å†…å®¹å¾€å¾€ä»¥æ›´é«˜çš„æ°´å¹³åšå‡ºäº†è§£é‡Šã€‚æˆ‘ä»¬ä¹ŸåŒ…æ‹¬äº†åŸå§‹å‡ºç‰ˆå¹´ä»½ï¼Œä»¥ä¾¿æ‚¨å¯ä»¥è¿½è¸ªåŸºç¡€ç ”ç©¶çš„å‘å±•ã€‚ï¼‰

### å¤§å‹è¯­è¨€æ¨¡å‹

#### æ–°æ¨¡å‹

**[Attention is all you need](https://arxiv.org/abs/1706.03762)** (2017)ï¼šè¿™æ˜¯ç”±Google Brainéƒ¨é—¨å‘å¸ƒçš„ï¼Œå¼•å‘äº†æ‰€æœ‰è½¬å˜çš„åŸå§‹Transformerå·¥ä½œå’Œç ”ç©¶è®ºæ–‡ã€‚ï¼ˆ[åšå®¢æ–‡ç« ](https://ai.googleblog.com/2017/08/transformer-novel-neural-network.html)ï¼‰

**[BERT: pre-training of deep bidirectional transformers for language understanding](https://arxiv.org/abs/1810.04805)** ï¼ˆ2018 å¹´ï¼‰ï¼šè¿™æ˜¯é¦–æ‰¹å…¬å¼€å¯ç”¨çš„LLMä¹‹ä¸€ï¼Œè‡³ä»Šä»æœ‰è®¸å¤šå˜ä½“åœ¨ä½¿ç”¨ã€‚ï¼ˆ[åšå®¢æ–‡ç« ](https://ai.googleblog.com/2018/11/open-sourcing-bert-state-of-art-pre.html)ï¼‰

**[Improving language understanding by generative pre-training](https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf)** (2018)ï¼šè¿™æ˜¯OpenAIå‘å¸ƒçš„é¦–ç¯‡è®ºæ–‡ï¼Œæ¶µç›–äº†GPTæ¶æ„ï¼Œå®ƒå·²æˆä¸ºLLMå‘å±•çš„ä¸»è¦è·¯å¾„ã€‚ï¼ˆ[åšå®¢æ–‡ç« ](https://openai.com/research/language-unsupervised)ï¼‰

**[Language models are few-shot learners](https://arxiv.org/abs/2005.14165)** (2020)ï¼šè¿™æ˜¯OpenAIçš„è®ºæ–‡ï¼Œæè¿°äº†GPT-3å’Œç°ä»£LLMçš„ä»…è§£ç å™¨æ¶æ„ã€‚ï¼ˆDecoder-only architectureï¼‰

**[Training language models to follow instructions with human feedback](https://arxiv.org/abs/2203.02155)** (2022)ï¼šè¿™æ˜¯OpenAIçš„è®ºæ–‡ï¼Œè§£é‡Šäº†InstructGPTï¼Œå®ƒåˆ©ç”¨äº†äººåœ¨å¾ªç¯è®­ç»ƒæ¨¡å‹ï¼Œä»è€Œæ›´å¥½åœ°éµå¾ªæç¤ºä¸­çš„æŒ‡ä»¤ã€‚è¿™æ˜¯ä½¿LLMèƒ½å¤Ÿä¸ºæ¶ˆè´¹è€…ï¼ˆä¾‹å¦‚ï¼Œé€šè¿‡ChatGPTï¼‰ä½¿ç”¨çš„å…³é”®çªç ´ä¹‹ä¸€ã€‚ï¼ˆ[åšå®¢æ–‡ç« ](https://openai.com/research/instruction-following)ï¼‰

**[LaMDA: language models for dialog applications](https://arxiv.org/abs/2201.08239)** ï¼ˆ2022 å¹´ï¼‰ï¼šè¿™æ˜¯Googleä¸“é—¨è®¾è®¡çš„æ¨¡å‹ï¼Œç”¨äºäººç±»å’ŒèŠå¤©æœºå™¨äººåœ¨å„ç§ä¸»é¢˜ä¸Šçš„è‡ªç”±å¯¹è¯ã€‚ï¼ˆ[åšå®¢æ–‡ç« ](https://blog.google/technology/ai/lamda/)ï¼‰ 

**[PaLM: Scaling language modeling with pathways](https://arxiv.org/abs/2204.02311)** ï¼ˆ2022 å¹´ï¼‰ï¼šGoogleçš„PaLMåˆ©ç”¨äº†ä¸€ç§æ–°ç³»ç»Ÿï¼Œå¯ä»¥åœ¨æ•°åƒä¸ªèŠ¯ç‰‡ä¸Šè®­ç»ƒLLMï¼Œå¹¶ä¸”éšç€æ¨¡å‹è§„æ¨¡çš„å¢å¤§ï¼Œåœ¨æŸäº›ä»»åŠ¡ä¸Šå±•ç¤ºå‡ºäº†è¶…é¢„æœŸçš„æ”¹è¿›ã€‚ï¼ˆ[åšå®¢æ–‡ç« ](https://ai.googleblog.com/2022/04/pathways-language-model-palm-scaling-to.html)ï¼‰ã€‚å¦è¯·å‚é˜…[PaLM-2 æŠ€æœ¯æŠ¥å‘Š](https://arxiv.org/abs/2305.10403)ã€‚

**[OPTï¼šOpen Pre-trained Transformer language models](https://arxiv.org/abs/2205.01068)** (2022)ï¼šOPTæ˜¯è¡¨ç°æœ€ä¼˜ç§€çš„å…¨å¼€æºLLMä¹‹ä¸€ã€‚è¿™ä¸ªæ‹¥æœ‰1750äº¿å‚æ•°çš„æ¨¡å‹çš„å‘å¸ƒé™„å¸¦äº†ä»£ç ï¼Œå¹¶åœ¨å…¬å¼€å¯ç”¨çš„æ•°æ®é›†ä¸Šè¿›è¡Œäº†è®­ç»ƒã€‚ï¼ˆ[åšå®¢æ–‡ç« ](https://ai.facebook.com/blog/democratizing-access-to-large-scale-language-models-with-opt-175b/)ï¼‰

**[Training compute-optimal large language models](https://arxiv.org/abs/2203.15556)**(2022)ï¼šChinchillaè®ºæ–‡ã€‚å®ƒæå‡ºå¤§å¤šæ•°æ¨¡å‹å—åˆ°æ•°æ®é™åˆ¶ï¼Œè€Œä¸æ˜¯è®¡ç®—é™åˆ¶ï¼Œå¹¶æ”¹å˜äº†å¯¹LLMè§„æ¨¡çš„å…±è¯†ã€‚ï¼ˆ[åšå®¢æ–‡ç« ](https://www.deepmind.com/blog/an-empirical-analysis-of-compute-optimal-large-language-model-training)ï¼‰

**[GPT-4 technical report](https://arxiv.org/abs/2303.08774)** ï¼ˆ2023 å¹´ï¼‰ï¼šæ¥è‡ªOpenAIçš„æœ€æ–°å’Œæœ€ä¼Ÿå¤§çš„è®ºæ–‡ï¼Œæœ€ä¸ºäººæ‰€çŸ¥çš„æ˜¯å®ƒæ­ç¤ºçš„ä¿¡æ¯ä¹‹å°‘ï¼ï¼ˆ[åšå®¢æ–‡ç« ](https://openai.com/research/gpt-4)ï¼‰ã€‚[GPT-4 ç³»ç»Ÿå¡ç‰‡](https://cdn.openai.com/papers/gpt-4-system-card.pdf)æ­ç¤ºäº†OpenAIå¦‚ä½•å¤„ç†å¹»è§‰ã€éšç§ã€å®‰å…¨æ€§å’Œå…¶ä»–é—®é¢˜ã€‚ã€‚

**[LLaMA: Open and efficient foundation language models](https://arxiv.org/abs/2302.13971)** (2023)ï¼šæ¥è‡ªMetaçš„æ¨¡å‹ï¼ˆå‡ ä¹ï¼‰å¼€å§‹äº†ä¸€ä¸ªå¼€æºLLMé©å‘½ã€‚ä¸è®¸å¤šæœ€å¥½çš„é—­æºæ¨¡å‹ç«äº‰ï¼Œä½†åªå¯¹ç ”ç©¶äººå‘˜å¼€æ”¾äº†æœ‰é™åˆ¶çš„è®¸å¯ã€‚ï¼ˆ[åšå®¢æ–‡ç« ](https://ai.facebook.com/blog/large-language-model-llama-meta-ai/)ï¼‰

**[Alpaca: A strong, replicable instruction-following model](https://crfm.stanford.edu/2023/03/13/alpaca.html)** ï¼ˆ2023 å¹´ï¼‰ï¼šæ¥è‡ªæ–¯å¦ç¦å¤§å­¦çš„è¿™ç§æ¨¡å‹å±•ç¤ºäº†æŒ‡ä»¤è°ƒæ•´çš„åŠ›é‡ï¼Œç‰¹åˆ«æ˜¯åœ¨è¾ƒå°çš„å¼€æºæ¨¡å‹ä¸­ï¼Œç›¸æ¯”äºçº¯ç²¹çš„è§„æ¨¡ã€‚

#### æ¨¡å‹æ”¹è¿›ï¼ˆä¾‹å¦‚å¾®è°ƒã€æ£€ç´¢ã€æ³¨æ„åŠ›ï¼‰

**[Deep reinforcement learning from human preferences](https://proceedings.neurips.cc/paper_files/paper/2017/file/d5e2c0adad503c91f91df240d0cd4e49-Paper.pdf)** (2017)ï¼šå…³äºæ¸¸æˆå’Œæœºå™¨äººç¯å¢ƒä¸­å¼ºåŒ–å­¦ä¹ çš„ç ”ç©¶ï¼Œç»“æœè¯æ˜è¿™æ˜¯ LLM çš„ç»ä½³å·¥å…·ã€‚

**[Retrieval-augmented generation for knowledge-intensive NLP tasks](https://arxiv.org/abs/2005.11401)** (2020)ï¼šç”± Facebook å¼€å‘ï¼ŒRAG æ˜¯é€šè¿‡ä¿¡æ¯æ£€ç´¢æé«˜ LLM å‡†ç¡®æ€§çš„ä¸¤ä¸ªä¸»è¦ç ”ç©¶è·¯å¾„ä¹‹ä¸€ã€‚ï¼ˆ[åšå®¢æ–‡ç« ](https://ai.facebook.com/blog/retrieval-augmented-generation-streamlining-the-creation-of-intelligent-natural-language-processing-models/)ï¼‰

**[Improving language models by retrieving from trillions of tokens ](https://arxiv.org/abs/2112.04426)** ï¼ˆ2021 å¹´ï¼‰ï¼šRETROï¼Œå³â€œæ£€ç´¢å¢å¼ºå‹ TRansfOrmersâ€ï¼Œè¿™æ˜¯å¦ä¸€ç§ç”±DeepMindæå‡ºçš„é€šè¿‡è®¿é—®è®­ç»ƒæ•°æ®ä¸­æœªåŒ…å«çš„ä¿¡æ¯æ¥æé«˜LLMå‡†ç¡®æ€§çš„æ–¹æ³•ã€‚ï¼ˆ[åšå®¢æ–‡ç« ](https://www.deepmind.com/blog/improving-language-models-by-retrieving-from-trillions-of-tokens)ï¼‰

**[LoRAï¼šLow-rank adaptation of large language models](https://arxiv.org/abs/2106.09685)** (2021)ï¼šè¿™é¡¹æ¥è‡ªMicrosoftçš„ç ”ç©¶ä¸ºåœ¨æ–°æ•°æ®ä¸Šè®­ç»ƒLLMæä¾›äº†ä¸€ç§æ¯”å¾®è°ƒæ›´æœ‰æ•ˆçš„æ›¿ä»£æ–¹æ¡ˆã€‚å®ƒç°åœ¨å·²ç»æˆä¸ºç¤¾åŒºå¾®è°ƒçš„æ ‡å‡†ï¼Œç‰¹åˆ«æ˜¯å¯¹äºå›¾åƒæ¨¡å‹ã€‚

**[Constitutional AI ](https://arxiv.org/abs/2212.08073)**(2022)ï¼šAnthropicå›¢é˜Ÿä»‹ç»äº†æ¥è‡ªAIåé¦ˆçš„å¼ºåŒ–å­¦ä¹ ï¼ˆRLAIFï¼‰çš„æ¦‚å¿µã€‚ä¸»è¦çš„æƒ³æ³•æ˜¯æˆ‘ä»¬å¯ä»¥åœ¨å…¶ä»–AIçš„ç›‘ç£ä¸‹å¼€å‘å‡ºä¸€ä¸ªæ— å®³çš„AIåŠ©æ‰‹ã€‚

**[FlashAttention: Fast and memory-efficient exact attention with IO-awareness](https://arxiv.org/abs/2205.14135)** ï¼ˆ2022ï¼‰ï¼šè¿™é¡¹æ¥è‡ªæ–¯å¦ç¦çš„ç ”ç©¶ä¸ºæœ€å…ˆè¿›çš„æ¨¡å‹æ‰“å¼€äº†ç†è§£æ›´é•¿æ–‡æœ¬åºåˆ—ï¼ˆå’Œé«˜åˆ†è¾¨ç‡å›¾åƒï¼‰è€Œæ— éœ€é«˜æ˜‚çš„è®­ç»ƒæ—¶é—´å’Œæˆæœ¬çš„å¤§é—¨ã€‚ï¼ˆ[åšå®¢æ–‡ç« ](https://ai.stanford.edu/blog/longer-sequences-next-leap-ai/)ï¼‰

**[Hungry hungry hippos: Towards language modeling with state space models](https://arxiv.org/abs/2212.14052)** (2022)ï¼šåŒæ ·æ¥è‡ªæ–¯å¦ç¦ï¼Œè¿™ç¯‡è®ºæ–‡æè¿°äº†è¯­è¨€å»ºæ¨¡ä¸­æ³¨æ„åŠ›çš„ä¸»è¦æ›¿ä»£æ–¹æ¡ˆä¹‹ä¸€ã€‚è¿™æ˜¯ä¸€æ¡é€šå‘æ›´å¥½çš„æ‰©å±•å’Œè®­ç»ƒæ•ˆç‡çš„æœ‰å‰é€”çš„è·¯å¾„ã€‚ï¼ˆ[åšå®¢æ–‡ç« ](https://hazyresearch.stanford.edu/blog/2023-01-20-h3)ï¼‰

### å›¾åƒç”Ÿæˆæ¨¡å‹

**[Learning transferable visual models from natural language supervision](https://arxiv.org/abs/2103.00020)** (2021)ï¼šè¿™ç¯‡è®ºæ–‡ä»‹ç»äº†ä¸€ç§åŸºç¡€æ¨¡å‹ CLIP ï¼Œå°†æ–‡æœ¬æè¿°ä¸å›¾åƒè”ç³»èµ·æ¥ã€‚è¿™æ˜¯è®¡ç®—æœºè§†è§‰ä¸­é¦–æ¬¡æœ‰æ•ˆçš„å¤§è§„æ¨¡ä½¿ç”¨åŸºç¡€æ¨¡å‹ã€‚ï¼ˆ[åšå®¢æ–‡ç« ](https://openai.com/research/clip)ï¼‰

**[Zero-shot text-to-image generation](https://arxiv.org/abs/2102.12092)** (2021)ï¼šè¿™ç¯‡è®ºæ–‡ä»‹ç»äº†DALL-Eï¼Œè¿™æ˜¯ä¸€ç§å°†ä¸Šè¿°çš„CLIPå’ŒGPT-3ç»“åˆèµ·æ¥ï¼Œæ ¹æ®æ–‡æœ¬æç¤ºè‡ªåŠ¨ç”Ÿæˆå›¾åƒçš„æ¨¡å‹ã€‚å®ƒçš„åç»§è€…ï¼ŒDALL-E 2ï¼Œåœ¨2022å¹´å¼•å‘äº†åŸºäºå›¾åƒçš„ç”Ÿæˆå¼AIçƒ­æ½®ã€‚ï¼ˆ[åšå®¢æ–‡ç« ](https://openai.com/research/dall-e)ï¼‰

**[High-resolution image synthesis with latent diffusion models](https://arxiv.org/abs/2112.10752)** (2021)ï¼šæè¿°ç¨³å®šæ‰©æ•£çš„è®ºæ–‡ï¼ˆåœ¨å‘å¸ƒå’Œçˆ†ç‚¸æ€§å¼€æºå¢é•¿ä¹‹åï¼‰ã€‚

**[Photorealistic text-to-image diffusion models with deep language understanding](https://arxiv.org/abs/2205.11487)** ï¼ˆ2022 å¹´ï¼‰ï¼šImagenæ˜¯Googleè¿›å…¥AIå›¾åƒç”Ÿæˆé¢†åŸŸçš„å°è¯•ã€‚å°½ç®¡åœ¨å®£å¸ƒåçš„ä¸€å¹´å¤šæ—¶é—´é‡Œï¼Œè¯¥æ¨¡å‹æˆªæ­¢åˆ°æœ¬æ–‡å‘å¸ƒæ—¥æœŸä»æœªå…¬å¼€å‘å¸ƒã€‚ï¼ˆ[ç½‘ç«™](https://imagen.research.google/)ï¼‰

**[DreamBoothï¼šFine tuning text-to-image diffusion models for subject-driven generation](https://arxiv.org/abs/2208.12242)** (2022)ï¼šDreamBoothæ˜¯Googleå¼€å‘çš„ä¸€ç§ç³»ç»Ÿï¼Œç”¨äºè®­ç»ƒæ¨¡å‹è¯†åˆ«ç”¨æˆ·æäº¤çš„ä¸»é¢˜ï¼Œå¹¶å°†å…¶åº”ç”¨åˆ°æç¤ºçš„ä¸Šä¸‹æ–‡ä¸­ï¼ˆä¾‹å¦‚ [ç”¨æˆ·] åœ¨è‰¾è²å°”é“å¡”ä¸‹å¾®ç¬‘ï¼‰ã€‚ï¼ˆ[ç½‘ç«™](https://dreambooth.github.io/)ï¼‰

**[Adding conditional control to text-to-image diffusion models](https://arxiv.org/abs/2302.05543)** (2023)ï¼šè¿™ç¯‡æ¥è‡ªæ–¯å¦ç¦çš„è®ºæ–‡ä»‹ç»äº†ControlNetï¼Œè¿™ç°åœ¨æ˜¯ä¸€ç§éå¸¸æµè¡Œçš„å·¥å…·ï¼Œç”¨äºå¯¹ä½¿ç”¨æ½œåœ¨æ‰©æ•£æ¨¡å‹çš„å›¾åƒç”Ÿæˆè¿›è¡Œç»†ç²’åº¦æ§åˆ¶ã€‚

### Agentsï¼ˆæ™ºèƒ½ä½“ä»£ç†ï¼‰

**[A path to autonomous machine intelligence](https://openreview.net/pdf?id=BZ5a1r-kVsf)** (2022)ï¼šMeta AIé¢†å¯¼è€…å’Œçº½çº¦å¤§å­¦æ•™æˆYann LeCunæå‡ºçš„å…³äºå¦‚ä½•æ„å»ºçœŸæ­£ç†è§£å‘¨å›´ä¸–ç•Œçš„è‡ªä¸»æ™ºèƒ½ä»£ç†çš„å»ºè®®ã€‚

**[ReActï¼šSynergizing reasoning and acting in language models](https://arxiv.org/abs/2210.03629)** (2022)ï¼šæ™®æ—æ–¯é¡¿å¤§å­¦å’ŒGoogleçš„ä¸€ä¸ªé¡¹ç›®ï¼Œç”¨æ¥æµ‹è¯•å’Œæé«˜LLMï¼ˆå¤§å‹è¯­è¨€æ¨¡å‹ï¼‰çš„æ¨ç†å’Œè§„åˆ’èƒ½åŠ›ã€‚ï¼ˆ[åšå®¢æ–‡ç« ](https://ai.googleblog.com/2022/11/react-synergizing-reasoning-and-acting.html)ï¼‰

**[Generative agents: Interactive simulacra of human behavior](https://arxiv.org/abs/2304.03442)** (2023)ï¼šæ–¯å¦ç¦å¤§å­¦å’ŒGoogleçš„ç ”ç©¶äººå‘˜ä½¿ç”¨LLMé©±åŠ¨ä»£ç†ï¼Œåœ¨ç±»ä¼¼äºâ€œThe Simsâ€ï¼ˆæ¨¡æ‹Ÿäººç”Ÿï¼‰è¿™æ ·çš„ç¯å¢ƒä¸­ï¼Œå…¶äº’åŠ¨æ˜¯è‡ªå‘çš„ï¼Œè€Œä¸æ˜¯ç”±ç¼–ç¨‹é©±åŠ¨çš„ã€‚

**[Reflexion: an autonomous agent with dynamic memory and self-reflection](https://arxiv.org/abs/2303.11366)** (2023)ï¼šæ¥è‡ªä¸œåŒ—å¤§å­¦å’ŒMITçš„ç ”ç©¶äººå‘˜çš„å·¥ä½œï¼Œä»–ä»¬é€šè¿‡ä»é”™è¯¯å’Œè¿‡å»çš„ç»éªŒä¸­å­¦ä¹ ï¼Œæ•™å¯¼LLMæ›´å¯é åœ°è§£å†³é—®é¢˜ã€‚

**[Toolformerï¼šLanguage models can teach themselves to use tools](https://arxiv.org/abs/2302.04761)** (2023)ï¼šè¿™ä¸ªæ¥è‡ªMetaçš„é¡¹ç›®è®­ç»ƒLLMä½¿ç”¨å¤–éƒ¨å·¥å…·ï¼ˆåœ¨è¿™ç§æƒ…å†µä¸‹ï¼ŒAPIæŒ‡å‘æœç´¢å¼•æ“å’Œè®¡ç®—å™¨ç­‰ä¸œè¥¿ï¼‰ï¼Œä»¥æé«˜å‡†ç¡®æ€§ï¼Œè€Œä¸å¢åŠ æ¨¡å‹å¤§å°ã€‚ 

**[Auto-GPT: An autonomous GPT-4 experiment](https://github.com/Significant-Gravitas/Auto-GPT)** : ä¸€ä¸ªå¼€æºå®éªŒé¡¹ç›®ï¼Œé€šè¿‡ç»™GPT-4æä¾›ä¸€ç»„å·¥å…·ï¼ˆäº’è”ç½‘è®¿é—®ã€æ–‡ä»¶å­˜å‚¨ç­‰ï¼‰å¹¶é€‰æ‹©ä½¿ç”¨å“ªäº›å·¥å…·æ¥è§£å†³ç‰¹å®šä»»åŠ¡ï¼Œä»¥æ‰©å¤§GPT-4çš„èƒ½åŠ›ã€‚

**[BabyAGI](https://github.com/yoheinakajima/babyagi)** ï¼šè¿™ä¸ªPythonè„šæœ¬ä½¿ç”¨GPT-4å’Œå‘é‡æ•°æ®åº“ï¼ˆç”¨æ¥å­˜å‚¨ä¸Šä¸‹æ–‡ï¼‰ï¼Œä»¥ä¾¿è®¡åˆ’å¹¶æ‰§è¡Œä¸€ç³»åˆ—è§£å†³æ›´å¹¿æ³›ç›®æ ‡çš„ä»»åŠ¡ã€‚

### å…¶ä»–æ•°æ®æ¨¡æ€

#### ä»£ç ç”Ÿæˆ

**[Evaluating large language models trained on code](https://arxiv.org/abs/2107.03374)** (2021)ï¼šè¿™æ˜¯OpenAIå…³äºCodexçš„ç ”ç©¶è®ºæ–‡ï¼ŒCodexæ˜¯GitHub Copilotäº§å“èƒŒåçš„ä»£ç ç”Ÿæˆæ¨¡å‹ã€‚ï¼ˆ[åšå®¢æ–‡ç« ](https://openai.com/blog/openai-codex)ï¼‰

**[Competition-level code generation with AlphaCode](https://www.science.org/stoken/author-tokens/ST-905/full)** ï¼ˆ2021 å¹´ï¼‰ï¼šè¿™é¡¹æ¥è‡ªDeepMindçš„ç ”ç©¶å±•ç¤ºäº†ä¸€ç§æ¨¡å‹ï¼Œèƒ½å¤Ÿæ¯”äººç±»ç¨‹åºå‘˜ç¼–å†™æ›´å¥½çš„ä»£ç ã€‚ï¼ˆ[åšå®¢æ–‡ç« ](https://www.deepmind.com/blog/competitive-programming-with-alphacode)ï¼‰

**[CodeGen: An open large language model for code with multi-turn program synthesis](https://arxiv.org/abs/2203.13474)** ï¼ˆ2022 å¹´ï¼‰ï¼šCodeGenæ¥è‡ªSalesforceçš„AIç ”ç©¶éƒ¨é—¨ï¼Œç›®å‰æ”¯æŒReplit Ghostwriterçš„ä»£ç ç”Ÿæˆäº§å“ã€‚ï¼ˆ[åšå®¢æ–‡ç« ](https://blog.salesforceairesearch.com/codegen/)ï¼‰

#### è§†é¢‘ç”Ÿæˆ

**[Make-A-Video: Text-to-video generation without text-video data ](https://arxiv.org/abs/2209.14792)** ï¼ˆ2022ï¼‰ï¼šæ¥è‡ªMetaçš„ä¸€ä¸ªæ¨¡å‹ï¼Œå¯ä»¥æ ¹æ®æ–‡æœ¬æç¤ºåˆ›å»ºçŸ­è§†é¢‘ï¼Œä¹Ÿå¯ä»¥ç»™é™æ€ç…§ç‰‡è¾“å…¥æ·»åŠ åŠ¨ä½œï¼Œæˆ–è€…åˆ›å»ºç°æœ‰è§†é¢‘çš„å˜ä½“ã€‚ï¼ˆ[åšå®¢æ–‡ç« ](https://makeavideo.studio/)ï¼‰

**[Imagen Video: High definition video generation with diffusion models](https://arxiv.org/abs/2210.02303)** ï¼ˆ2022 å¹´ï¼‰ï¼šé¡¾åæ€ä¹‰ï¼šè°·æ­ŒåŸºäºå›¾åƒçš„ Imagen æ¨¡å‹çš„ä¸€ä¸ªç‰ˆæœ¬ï¼Œä¸“é—¨ç”¨äºæ ¹æ®æ–‡æœ¬æç¤ºç”ŸæˆçŸ­è§†é¢‘ã€‚ï¼ˆ[ç½‘ç«™](https://imagen.research.google/video/)ï¼‰

#### äººç±»ç”Ÿç‰©å­¦å’ŒåŒ»å­¦æ•°æ®

**[Strategies for pre-training graph neural networks](https://arxiv.org/pdf/1905.12265.pdf)** (2020)ï¼šè¿™ç¯‡å‡ºç‰ˆç‰©ä¸ºæœ‰æ•ˆçš„é¢„è®­ç»ƒæ–¹æ³•å¥ å®šäº†åŸºç¡€ï¼Œè¿™äº›æ–¹æ³•å¯¹äºè¯ç‰©å‘ç°çš„å„ç§åº”ç”¨éƒ½å¾ˆæœ‰ç”¨ï¼Œæ¯”å¦‚åˆ†å­æ€§è´¨é¢„æµ‹å’Œè›‹ç™½è´¨åŠŸèƒ½é¢„æµ‹ã€‚ï¼ˆ[åšå®¢æ–‡ç« ](https://snap.stanford.edu/gnn-pretrain/)ï¼‰

**[Improved protein structure prediction using potentials from deep learning](https://www.nature.com/articles/s41586-019-1923-7)** ï¼ˆ2020 å¹´ï¼‰ï¼šDeepMindçš„ä»¥è›‹ç™½è´¨ä¸ºä¸­å¿ƒçš„Transformeræ¨¡å‹AlphaFoldï¼Œä½¿å¾—èƒ½å¤Ÿä»åºåˆ—é¢„æµ‹è›‹ç™½è´¨ç»“æ„â€”â€”è¿™æ˜¯ä¸€ä¸ªçœŸæ­£çš„çªç ´ï¼Œå·²ç»å¯¹ç†è§£ç”Ÿç‰©è¿‡ç¨‹å’Œå¼€å‘æ–°çš„ç–¾ç—…æ²»ç–—æ–¹æ³•äº§ç”Ÿäº†æ·±è¿œå½±å“ã€‚ï¼ˆ[åšå®¢æ–‡ç« ](https://www.deepmind.com/blog/alphafold-a-solution-to-a-50-year-old-grand-challenge-in-biology)ï¼‰ï¼ˆ[è§£é‡Šå™¨](https://www.blopig.com/blog/2021/07/alphafold-2-is-here-whats-behind-the-structure-prediction-miracle/)ï¼‰

**[Large language models encode clinical knowledge](https://arxiv.org/abs/2212.13138)** ï¼ˆ2022ï¼‰ï¼šMed-PaLMæ˜¯ä¸€ä¸ªèƒ½å¤Ÿæ­£ç¡®å›ç­”ç¾å›½åŒ»ç–—æ‰§ç…§è€ƒè¯•é£æ ¼é—®é¢˜çš„LLMã€‚è¯¥å›¢é˜Ÿå·²ç»å…¬å¸ƒäº†Med-PaLM2çš„è¡¨ç°ç»“æœï¼Œå…¶å¾—åˆ†ä¸â€œä¸“å®¶â€è€ƒè¯•è€…ç›¸å½“ã€‚å…¶ä»–å›¢é˜Ÿå·²ç»ç”¨[ChatGPT](https://www.medrxiv.org/content/10.1101/2022.12.19.22283643v2)å’Œ[GPT-4](https://arxiv.org/abs/2303.13375)è¿›è¡Œäº†ç±»ä¼¼çš„å®éªŒã€‚ï¼ˆ[è§†é¢‘](https://www.youtube.com/watch?v=saWEFDRuNJc)ï¼‰

#### éŸ³é¢‘ç”Ÿæˆ

**[Jukebox: A generative model for music](https://arxiv.org/abs/2005.00341)** ï¼ˆ2020 å¹´ï¼‰ï¼šOpenAIä½¿ç”¨transformerè¿›è¡ŒéŸ³ä¹ç”Ÿæˆçš„å°è¯•ï¼Œèƒ½å¤Ÿåœ¨æœ€å°çš„è®­ç»ƒä¸‹ç”ŸæˆéŸ³ä¹ã€å£°éŸ³å’Œæ­Œè¯ã€‚ï¼ˆ[åšå®¢æ–‡ç« ](https://openai.com/research/jukebox)ï¼‰

**[AudioLM: a language modeling approach to audio generation](https://arxiv.org/pdf/2209.03143.pdf)** (2022)ï¼šAudioLMæ˜¯Googleçš„ä¸€ä¸ªé¡¹ç›®ï¼Œç”¨äºç”Ÿæˆå¤šç§ç±»å‹çš„éŸ³é¢‘ï¼ŒåŒ…æ‹¬è¯­éŸ³å’Œä¹å™¨æ¼”å¥ã€‚ï¼ˆ[åšå®¢æ–‡ç« ](https://ai.googleblog.com/2022/10/audiolm-language-modeling-approach-to.html)ï¼‰

**[MusicLM: Generating nusic from text](https://arxiv.org/abs/2301.11325)** (2023)ï¼šå½“å‰åŸºäºAIçš„éŸ³ä¹ç”Ÿæˆçš„æœ€æ–°æŠ€æœ¯ï¼Œå±•ç¤ºå‡ºæ¯”ä»¥å‰å°è¯•æ›´é«˜çš„è´¨é‡å’Œè¿è´¯æ€§ã€‚ï¼ˆ[åšå®¢æ–‡ç« ](https://google-research.github.io/seanet/musiclm/examples/)ï¼‰

#### å¤šç»´å›¾åƒç”Ÿæˆ

**[NeRFï¼šRepresenting scenes as neural radiance fields for view synthesis](https://arxiv.org/abs/2003.08934)** (2020)ï¼šæ¥è‡ªä»¥åŠ å·å¤§å­¦ä¼¯å…‹åˆ©åˆ†æ ¡ä¸ºä¸»çš„å›¢é˜Ÿçš„ç ”ç©¶ï¼Œä½¿ç”¨5Dåæ ‡â€œåˆæˆå¤æ‚åœºæ™¯çš„æ–°è§†å›¾â€ã€‚ï¼ˆ[ç½‘ç«™](https://www.matthewtancik.com/nerf)ï¼‰

**[DreamFusion: Text-to-3D using 2D diffusion](https://arxiv.org/pdf/2209.14988.pdf)** (2022)ï¼šæ¥è‡ªGoogleå’ŒåŠ å·å¤§å­¦ä¼¯å…‹åˆ©åˆ†æ ¡çš„ç ”ç©¶äººå‘˜çš„å·¥ä½œï¼ŒåŸºäºNeRFä»2Dè¾“å…¥ç”Ÿæˆ3Då›¾åƒã€‚ï¼ˆ[ç½‘ç«™](https://dreamfusion3d.github.io/)ï¼‰
