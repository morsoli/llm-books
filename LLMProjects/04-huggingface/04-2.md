æœ¬ç”µå­ä¹¦å¼€æºï¼Œæ¬¢è¿ star ğŸŒŸï¼Œå…³æ³¨ã€ŠLLM åº”ç”¨å¼€å‘å®è·µç¬”è®°ã€‹

> **äº¤æµç¾¤** åˆ›å»ºäº†ä¸€ä¸ªLLMåº”ç”¨å¼€å‘äº¤æµç¾¤ï¼Œæœ‰éœ€è¦çš„å¯ä»¥é€‰æ‹©åŠ å…¥
![](../images/group.png)

## transformers åº“åŸºç¡€ç»„ä»¶


### Pipline ç»„ä»¶

#### pipelineçš„å®šä¹‰å’Œç»„æˆ

- æµæ°´çº¿æ˜¯å°†æ•°æ®é¢„å¤„ç†ã€æ¨¡å‹è°ƒç”¨å’Œæ¨¡å‹ç»“æœåå¤„ç†ç»„è£…æˆä¸€ä¸ªæµæ°´çº¿ã€‚
- æµæ°´çº¿ç®€åŒ–äº†æ¨ç†ä»£ç ï¼Œè®©ç”¨æˆ·èƒ½å¤Ÿç›´æ¥è¾“å…¥æ–‡æœ¬å¹¶å¾—åˆ°æœ€ç»ˆç»“æœã€‚
- æµæ°´çº¿çš„å·¥ä½œåŒ…æ‹¬tokenizationã€è¾“å…¥è½¬æ¢ã€æ¨¡å‹é¢„æµ‹ã€soft maxå’Œæ ‡ç­¾æ˜ å°„ç­‰ã€‚
- å¯ä»¥é€šè¿‡è°ƒç”¨æµæ°´çº¿æ¥å®Œæˆä¸åŒæ¨¡å‹çš„æ¨ç†ï¼Œæ— éœ€å…³æ³¨ç»†èŠ‚ï¼Œæµæ°´çº¿æ”¯æŒå¤šç§ä»»åŠ¡ç±»å‹ã€‚

#### pipelineæ”¯æŒçš„ä»»åŠ¡ç±»å‹

```
from transformers.pipelines import SUPPORTED_TASKS, get_supported_tasks

print(SUPPORTED_TASKS.items(), get_supported_tasks())
```

![image-20230827212802627](https://s2.loli.net/2023/08/27/bRksWOhtHNEmBof.png)

#### pipelineçš„åˆ›å»ºå’Œä½¿ç”¨æ–¹å¼

1. æ ¹æ®ä»»åŠ¡ç±»å‹ç›´æ¥åˆ›å»ºPipeline, é»˜è®¤éƒ½æ˜¯è‹±æ–‡çš„æ¨¡å‹

```
from transformers import pipeline

pipe = pipeline("text-classification")
pipe("very good!")
# [{'label': 'POSITIVE', 'score': 0.9998525381088257}]
```

2. æŒ‡å®šä»»åŠ¡ç±»å‹ï¼Œå†æŒ‡å®šæ¨¡å‹ï¼Œåˆ›å»ºåŸºäºæŒ‡å®šæ¨¡å‹çš„Pipeline

```
from transformers import pipeline

# https://huggingface.co/models
pipe = pipeline("text-classification", 
                model="uer/roberta-base-finetuned-dianping-chinese")
pipe("æˆ‘è§‰å¾—ä¸å¤ªè¡Œï¼")
# [{'label': 'negative (stars 1, 2 and 3)', 'score': 0.9735506772994995}]
```

3. é¢„å…ˆåŠ è½½æ¨¡å‹ï¼Œå†åˆ›å»ºPipeline

```
from transformers import AutoModelForSequenceClassification, AutoTokenizer, pipeline

model = AutoModelForSequenceClassification.from_pretrained("uer/roberta-base-finetuned-dianping-chinese")
tokenizer = AutoTokenizer.from_pretrained("uer/roberta-base-finetuned-dianping-chinese")

pipe = pipeline("text-classification", model=model, tokenizer=tokenizer)
pipe("ä½ çœŸæ˜¯ä¸ªäººæ‰ï¼")
# [{'label': 'positive (stars 4 and 5)', 'score': 0.8717765808105469}]
```

4. GPUæ¨ç†åŠ é€Ÿ

```
pipe = pipeline("text-classification", model="uer/roberta-base-finetuned-dianping-chinese", device=0)
pipe.model.device
# device(type='cuda', index=0)
```

#### pipelineçš„å®ç°åŸç†

1. åˆå§‹åŒ–Tokenizerï¼š  `tokenizer = AutoTokenizer.from_pretrained("uer/roberta-base-finetuned-dianping-chinese")`
2. åˆå§‹åŒ–Modelï¼š `model = AutoModelForSequenceClassification.from_pretrained("uer/roberta-base-finetuned-dianping-chinese")`

3. æ•°æ®é¢„å¤„ç†ï¼š

   ```
   input_text ="æˆ‘è§‰å¾—ä¸å¤ªè¡Œï¼"
   inputs = tokenizer(input_text, return_ tensors="pt")
   ```

4. æ¨¡å‹é¢„æµ‹ï¼š`res = model(**inputs).logits`

5. ç»“æœåå¤„ç†

   ```
   pred = torch.argmax(torch.softmax(logits, dim=-1)).item()
   result = model.config.id2label.get(pred)
   ```

   